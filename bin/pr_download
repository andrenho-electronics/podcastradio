#!/usr/bin/env python3

import configparser
import logging
import sqlite3
import time
import urllib.request
import threading
import xml.etree.ElementTree as ET  
from email.utils import parsedate_tz
from pprint import pprint

# CONFIG #######################################################################

class Config:
    def __init__(self):
        self.podcasts = []

def read_config_file():
    cfg = Config()
    config = configparser.ConfigParser(delimiters=('=',), allow_no_value=True)
    config.read('download.ini')
    for key in config['podcasts']:
        cfg.podcasts.append(key)
    cfg.keep_episodes = int(config['config']['keep_episodes'])
    cfg.download_path = config['config']['download_path']
    cfg.download_threads = int(config['config']['download_threads'])
    return cfg


# DATABASE #####################################################################

def open_database():

    def create_database_objects(conn):
        conn.cursor().execute('''
            CREATE TABLE IF NOT EXISTS podcasts (
                url           TEXT PRIMARY KEY,
                title         TEXT,
                keep_episodes INTEGER   DEFAULT 5
            );
        ''')
        conn.cursor().execute('''
            CREATE TABLE IF NOT EXISTS episodes (
                podcast_url   TEXT,
                episode_url   TEXT,
                title         TEXT,
                date          INTEGER,
                length        TEXT,
                nbytes        INTEGER,
                downloaded    BOOLEAN   DEFAULT 0,
                keep          BOOLEAN   DEFAULT 0,
                PRIMARY KEY(podcast_url, episode_url),
                FOREIGN KEY(podcast_url) REFERENCES podcasts(url)
            );
        ''')
        conn.cursor().execute('''
            CREATE TABLE IF NOT EXISTS downloads (
                url             TEXT,
                podcast_title   TEXT,
                episode_title   TEXT,
                thread          INTEGER  DEFAULT NULL,
                episode_size    INTEGER  DEFAULT NULL,
                bytes_downd     INTEGER  DEFAULT 0,
                PRIMARY KEY(url),
                FOREIGN KEY(url) REFERENCES episodes(episode_url)
            );
        ''')

    conn = sqlite3.connect('podcastradio.db')
    create_database_objects(conn)
    return conn


# PODCASTS #####################################################################

def check_podcasts(cfg, db):

    def check_config_against_db(cfg, db):
        c = db.cursor()
        urls_in_db = []
        # URLs in db but not in config - delete from DB
        for row in c.execute('SELECT url FROM podcasts'):
            if row[0] not in cfg.podcasts:
                c.execute('DELETE FROM podcasts WHERE url=?', (row[0],))
                logging.debug('URL ' + row[0] + ' was deleted from database.')
            else:
                urls_in_db.append(row[0])
        # URLs in config but not in db - insert to db
        for url in cfg.podcasts:
            if url not in urls_in_db:
                c.execute('INSERT INTO podcasts ( url, keep_episodes ) VALUES ( ?, ? )',
                        (url, cfg.keep_episodes))
                urls_in_db.append(url)
                logging.debug('URL ' + url + ' was inserted into database.')
        db.commit()
        return urls_in_db

    def download_podcast_rss(url):
        response = urllib.request.urlopen(url)
        data = response.read()
        xml = data.decode('utf-8')
        logging.debug('Podcast XML file downloaded from URL ' + url)
        return xml

    def parse_podcast_rss(xml):
        class PodcastInfo:
            pass
        class Episode:
            pass
        info = PodcastInfo()
        root = ET.fromstring(xml)
        info.title = root.find('./channel/title').text
        info.episodes = []
        for item in root.findall('./channel/item'):
            ep = Episode()
            ep.url = item.find('enclosure').attrib['url']
            ep.title = item.find('title').text
            ep.date = int(time.mktime(parsedate_tz(item.find('pubDate').text)[0:9]))  # date in unix timestamp format
            try:
                ep.length = item.find('{http://www.itunes.com/dtds/podcast-1.0.dtd}duration').text
            except AttributeError:
                pass
            info.episodes.append(ep)
        logging.debug('Parsed data from podcast RSS: ' + info.title)
        return info

    def update_podcast_database(url, db, info):
        db.cursor().execute('''
            UPDATE podcasts
               SET title = ?
             WHERE url = ?''', (info.title, url))
        for ep in info.episodes:
            db.cursor().execute('''
                INSERT OR REPLACE INTO episodes ( podcast_url, episode_url, title, date, length )
                                VALUES ( ?, ?, ?, ?, ? )''',
                (url, ep.url, ep.title, ep.date, ep.length))
        db.commit()
        logging.debug('Tables updated for podcast ' + info.title)

    urls = check_config_against_db(cfg, db)
    for url in urls:
        xml = download_podcast_rss(url)
        info = parse_podcast_rss(xml)
        update_podcast_database(url, db, info)


# EPISODES #####################################################################

def download_episodes(db, cfg):

    def remove_old_podcast_episodes(url, keep, db, cfg):
        for row in db.cursor().execute('''
            SELECT rowid, episode_url, title
              FROM episodes
             WHERE podcast_url = ?
               AND keep = 0
               AND downloaded = 1
          ORDER BY date DESC
             LIMIT -1 OFFSET ?''', (url, keep)):
            os.remove(cfg.download_path + '/' + row[0])
            db.cursor.execute('UPDATE episodes SET downloaded = 0 WHERE episode_url = ?', (row[1],))
            logging.debug("Removed episode '" + row[2] + "'")
        db.commit()

    def download_new_podcast_episodes(url, db):
        db.cursor().execute('''
            INSERT INTO downloads ( url, podcast_title, episode_title )
                 SELECT ep
        pass
        """
        for row in db.cursor().execute('''
            SELECT episode_url, title, downloaded
              FROM episodes
             WHERE podcast_url = ?
          ORDER BY date DESC
             LIMIT ?''', (url, cfg.keep_episodes)):
            if float(row[2]) < 1.0:
                download_queue[row[0]] = row[1]
        """

    for row in db.cursor().execute('SELECT url, keep_episodes FROM podcasts'):
        url = row[0]
        remove_old_podcast_episodes(url, row[1], db, cfg)
        download_new_podcast_episodes(url, db)


# DOWNLOAD THREAD ##############################################################

class DownloadThread(threading.Thread):

    counter = 0

    def __init__(self, db):
        threading.Thread.__init__(self)
        self.db = db
        self.number = DownloadThread.counter
        DownloadThread.counter += 1

    def run(self):
        logging.debug('Download thread #' + str(self.number) + ' started.')
        while True:
            time.sleep(1)

# MAIN #########################################################################

if __name__ == '__main__':
    logging.basicConfig(level='DEBUG')
    db             = open_database()
    cfg            = read_config_file()

    for _ in range(0, cfg.download_threads):
        DownloadThread(db).start()

    while True:
        logging.debug('-------------------------------------------------------')
        logging.debug('Executing loop...')
        cfg = read_config_file()
        check_podcasts(cfg, db)
        download_episodes(db, cfg)
        logging.debug('Waiting for next loop...')
        time.sleep(120)

# vim: foldmethod=marker
