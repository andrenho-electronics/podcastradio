#!/usr/bin/env python3

import configparser
from email.utils import parsedate_tz
import logging
from pprint import pprint
import sqlite3
import time
import urllib.request
import xml.etree.ElementTree as ET  


# CONFIG #######################################################################

class Config:
    def __init__(self):
        self.podcasts = []

def read_config_file():
    cfg = Config()
    config = configparser.ConfigParser(delimiters=('=',), allow_no_value=True)
    config.read('download.ini')
    for key in config['podcasts']:
        cfg.podcasts.append(key)
    cfg.keep_episodes = int(config['config']['keep_episodes'])
    cfg.download_path = config['config']['download_path']
    return cfg


# DATABASE #####################################################################

def open_database():

    def create_database_objects(conn):
        conn.cursor().execute('''
            CREATE TABLE IF NOT EXISTS podcasts (
                url           TEXT PRIMARY KEY,
                title         TEXT,
                keep_episodes INTEGER   DEFAULT 5
            );
        ''')
        conn.cursor().execute('''
            CREATE TABLE IF NOT EXISTS episodes (
                podcast_url   TEXT,
                episode_url   TEXT,
                title         TEXT,
                date          INTEGER,
                length        TEXT,
                nbytes        INTEGER,
                perc_downl    REAL      DEFAULT 0.0,
                keep          BOOLEAN   DEFAULT 0,
                PRIMARY KEY(podcast_url, episode_url),
                FOREIGN KEY(podcast_url) REFERENCES podcasts(url)
            );
        ''')

    conn = sqlite3.connect('podcastradio.db')
    create_database_objects(conn)
    return conn


# PODCASTS #####################################################################

def check_podcasts(cfg, db):

    def check_config_against_db(cfg, db):
        c = db.cursor()
        urls_in_db = []
        # URLs in db but not in config - delete from DB
        for row in c.execute('SELECT url FROM podcasts'):
            if row[0] not in cfg.podcasts:
                c.execute('DELETE FROM podcasts WHERE url=?', (row[0],))
                logging.info('URL ' + row[0] + ' was deleted from database.')
            else:
                urls_in_db.append(row[0])
        # URLs in config but not in db - insert to db
        for url in cfg.podcasts:
            if url not in urls_in_db:
                c.execute('INSERT INTO podcasts ( url, keep_episodes ) VALUES ( ?, ? )',
                        (url, cfg.keep_episodes))
                urls_in_db.append(url)
                logging.info('URL ' + url + ' was inserted into database.')
        db.commit()
        return urls_in_db

    def download_podcast_rss(url):
        xml = download_file(url)
        logging.debug('Podcast XML file downloaded from URL ' + url)
        return xml

    def parse_podcast_rss(xml):
        class PodcastInfo:
            pass
        class Episode:
            pass
        info = PodcastInfo()
        root = ET.fromstring(xml)
        info.title = root.find('./channel/title').text
        info.episodes = []
        for item in root.findall('./channel/item'):
            ep = Episode()
            ep.url = item.find('enclosure').attrib['url']
            ep.title = item.find('title').text
            ep.date = int(time.mktime(parsedate_tz(item.find('pubDate').text)[0:9]))  # date in unix timestamp format
            try:
                ep.length = item.find('{http://www.itunes.com/dtds/podcast-1.0.dtd}duration').text
            except AttributeError:
                pass
            info.episodes.append(ep)
        logging.debug('Parsed data from podcast RSS: ' + info.title)
        return info

    def update_podcast_database(url, db, info):
        db.cursor().execute('''
            UPDATE podcasts
               SET title = ?
             WHERE url = ?''', (info.title, url))
        for ep in info.episodes:
            db.cursor().execute('''
                INSERT OR REPLACE INTO episodes ( podcast_url, episode_url, title, date, length )
                                VALUES ( ?, ?, ?, ?, ? )''',
                (url, ep.url, ep.title, ep.date, ep.length))
        db.commit()
        logging.debug('Tables updated for podcast ' + info.title)

    urls = check_config_against_db(cfg, db)
    for url in urls:
        xml = download_podcast_rss(url)
        info = parse_podcast_rss(xml)
        update_podcast_database(url, db, info)

# EPISODES #####################################################################

def download_episodes(db):

    def remove_old_podcast_episodes(url, keep, db):
        for row in db.cursor().execute('''
            SELECT rowid, episode_url
              FROM episodes
             WHERE podcast_url = ?
               AND keep = 0
               AND perc_downl > 0.0
          ORDER BY date DESC
             LIMIT -1 OFFSET ?''', (url, keep)):
            os.remove(cfg.download_path + '/' + row[0])
            db.cursor.execute('UPDATE episodes SET perc_downl = 0.0 WHERE episode_url = ?', (row[1],))
        db.commit()

    def download_new_podcast_episodes(url, db):
        pass

    for row in db.cursor().execute('SELECT url, keep_episodes FROM podcasts'):
        url = row[0]
        remove_old_podcast_episodes(url, row[1], db)
        download_new_podcast_episodes(url, db)

# UTIL #########################################################################

def download_file(url):
    response = urllib.request.urlopen(url)
    data = response.read()
    return data.decode('utf-8')


# MAIN #########################################################################

if __name__ == '__main__':
    logging.basicConfig(level='DEBUG')
    db = open_database()
    while True:
        logging.info('Executing loop...')
        cfg = read_config_file()
        check_podcasts(cfg, db)
        download_episodes(db)
        time.sleep(120)

# vim: foldmethod=marker
